{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total WAV files found: 10\n",
      "WAV Matrix shape: (10, 79565)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Define the root folder containing multiple subfolders\n",
    "root_folder = \"TEST/DR1/FAKS0\"  # Change this to your folder path\n",
    "\n",
    "# Recursively get all .wav files from all subdirectories\n",
    "file_paths = [str(file) for file in Path(root_folder).rglob(\"*.wav\")]\n",
    "\n",
    "# Read all wav files and store them in a list\n",
    "min_lgth = 0\n",
    "wav_data = []\n",
    "for file in file_paths:\n",
    "    data, _ = librosa.load(file, sr=None)  # Keep original sample rate\n",
    "    max_data= np.max(data)\n",
    "    data /= max_data\n",
    "    wav_data.append(data)\n",
    "    \n",
    "# Convert list to a matrix (pad shorter signals with zeros)\n",
    "max_length = max(len(x) for x in wav_data)  # Find max length of any audio file\n",
    "wav_matrix = np.array([np.pad(x, (0, max_length - len(x))) for x in wav_data])\n",
    "\n",
    "print(\"Total WAV files found:\", len(file_paths))\n",
    "print(\"WAV Matrix shape:\", wav_matrix.shape)  # (num_files, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79565, 10, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_matrix[np.isnan(wav_matrix)] = 0\n",
    "wav_matrix = wav_matrix.reshape((10, 79565, 1))\n",
    "wav_matrix = wav_matrix.reshape((79565, 10, 1))\n",
    "wav_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_matrix[np.isnan(wav_matrix)] = 0\n",
    "np.isnan(wav_matrix).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m X \u001b[38;5;241m=\u001b[39m wav_matrix\n\u001b[1;32m     16\u001b[0m n_kernels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 17\u001b[0m dico \u001b[38;5;241m=\u001b[39m \u001b[43mMultivariateDictLearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_kernels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_kernels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m residual, code \u001b[38;5;241m=\u001b[39m multivariate_sparse_encode(X, dico)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObjective error for each samples is:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/mdla/mdla/mdla.py:1367\u001b[0m, in \u001b[0;36mMultivariateDictLearning.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model from data in X.\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m \n\u001b[1;32m   1354\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;124;03m    Returns the object itself\u001b[39;00m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1366\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m-> 1367\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43marray3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1368\u001b[0m n_samples, n_features, n_dims \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernels_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/mdla/mdla/mdla.py:1662\u001b[0m, in \u001b[0;36marray3d\u001b[0;34m(X, dtype, order, copy, force_all_finite)\u001b[0m\n\u001b[1;32m   1660\u001b[0m     X_3d \u001b[38;5;241m=\u001b[39m X_3d\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1662\u001b[0m     \u001b[43massert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_3d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_3d\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:202\u001b[0m, in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_all_finite\u001b[39m(\n\u001b[1;32m    177\u001b[0m     X,\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    182\u001b[0m ):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;124;03m\"\"\"Throw a ValueError if X contains NaN or infinity.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m        documentation.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/mnt/d_disk/ch22b007/mdla\")  # Adjust the path accordingly\n",
    "\n",
    "from mdla import MiniBatchMultivariateDictLearning, MultivariateDictLearning\n",
    "\n",
    "from mdla import MultivariateDictLearning\n",
    "from mdla import multivariate_sparse_encode\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# rng_global = np.random.RandomState(0)\n",
    "# n_samples, n_features, n_dims = 10, 5, 3\n",
    "# X = rng_global.randn(n_samples, n_features, n_dims)\n",
    "X = wav_matrix\n",
    "\n",
    "n_kernels = 10\n",
    "dico = MultivariateDictLearning(n_kernels=n_kernels, max_iter=10).fit(X)\n",
    "residual, code = multivariate_sparse_encode(X, dico)\n",
    "print ('Objective error for each samples is:')\n",
    "for i in range(len(residual)):\n",
    "    print ('Sample', i, ':', norm(residual[i], 'fro') + len(code[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = dico.kernels_\n",
    "K = np.array(K)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(X[:, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = np.array(residual)\n",
    "code = np.array(code)\n",
    "print(np.shape(residual))\n",
    "print(np.shape(code))\n",
    "\n",
    "# np.array(residual[0, :, :])@np.array(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammatone_utils import *\n",
    "# from scikits.talkbox import segment_axis\n",
    "# from scikits.audiolab import Sndfile, play\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "import pydub \n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import matplotlib.pyplot as plt\n",
    "# from encoding1 import * \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def matching_pursuit(signal, dict_kernels, threshold=0.1, max_iter=2000):\n",
    "    \"\"\"\n",
    "    Matching pursuit algorithm for encoding\n",
    "    :param signal: input signal\n",
    "    :param dict_kernels: dictionary of kernels, each column is a kernel\n",
    "    :param threshold: stop condition\n",
    "    :param max_iter: maximum number of iterations\n",
    "    :return: array of scalar weighting factor (one per kernel)\n",
    "    \"\"\"\n",
    "    # Initialization\n",
    "    res = signal\n",
    "    coeff = np.zeros(dict_kernels.shape[0])\n",
    "    # Iterative decomposition\n",
    "    for i in range(max_iter):\n",
    "        inner_prod = res.dot(dict_kernels.T)\n",
    "        max_kernel = np.argmax(inner_prod)\n",
    "        coeff[max_kernel] = inner_prod[max_kernel] / np.linalg.norm(dict_kernels[max_kernel,: ])**2\n",
    "        res = res - coeff[max_kernel] * dict_kernels[max_kernel,: ]\n",
    "        if np.linalg.norm(res) < threshold:\n",
    "            return coeff\n",
    "    return coeff\n",
    "\n",
    "def segment_axis(arr, frame_size, overlap, end='pad'):\n",
    "    step = frame_size - overlap\n",
    "    if end == 'pad':\n",
    "        pad_width = (frame_size - (len(arr) % step)) % frame_size\n",
    "        arr = np.pad(arr, (0, pad_width), mode='constant')\n",
    "    \n",
    "    return np.lib.stride_tricks.sliding_window_view(arr, frame_size)[::step]\n",
    "\n",
    "# Parametrization\n",
    "b = 1.019\n",
    "resolution = 160\n",
    "step = 8\n",
    "n_channels = 128\n",
    "overlap = 50\n",
    "\n",
    "# Compute gammatone-based dictionary\n",
    "D_multi = np.r_[tuple(gammatone_matrix(b, fc, resolution, step)[0] for\n",
    "                      fc in erb_space(150, 8000, n_channels))]\n",
    "freq_c = np.array([gammatone_matrix(b, fc, resolution, step)[1] for\n",
    "                      fc in erb_space(150, 8000, n_channels)]).flatten()\n",
    "centers = np.array([gammatone_matrix(b, fc, resolution, step)[2] + i*resolution  for\n",
    "                      i, fc in enumerate(erb_space(150, 8000, n_channels))]).flatten()\n",
    "\n",
    "# Load test signal\n",
    "filename = 'TEST/DR1/FAKS0/SX403.wav'\n",
    "# f = Sndfile(filename, 'r')\n",
    "f, samplerate1 = sf.read(filename)\n",
    "f = sf.SoundFile(filename)\n",
    "\n",
    "nf = len(f) # f.nframes\n",
    "fs = samplerate1\n",
    "length_sound = 20000\n",
    "y = f.read(frames = length_sound)\n",
    "# y = f.read_frames(length_sound)\n",
    "\n",
    "Y = segment_axis(y, resolution, overlap=overlap, end='pad')\n",
    "Y = np.hanning(resolution) * Y\n",
    "\n",
    "# Encoding with matching pursuit\n",
    "X = np.zeros((Y.shape[0],D_multi.shape[0]))\n",
    "for idx in range(Y.shape[0]):\n",
    "    X[idx, :] = matching_pursuit(Y[idx, :], D_multi)\n",
    "\n",
    "# Reconstruction of the signal\n",
    "out = np.zeros(int((np.ceil(len(y)/resolution)+1)*resolution))\n",
    "for k in range(0, len(X)):\n",
    "    idx = range(k*(resolution-overlap), k*(resolution-overlap) + resolution)\n",
    "    out[idx] += np.dot(X[k], D_multi)\n",
    "squared_error = np.sum((y - out[0:len(y)]) ** 2)\n",
    "\n",
    "\n",
    "arr = np.array(range(length_sound))/float(fs)\n",
    "plt.figure(1)\n",
    "plt.subplot(311)\n",
    "plt.plot(arr, y, 'b', label=\"Input Signal\")\n",
    "plt.legend()\n",
    "plt.subplot(312)\n",
    "plt.plot(arr, out[0:len(y)], 'r', label=\"Recontruction\")\n",
    "plt.legend()\n",
    "plt.subplot(313)\n",
    "plt.plot(arr, (y - out[0:len(y)])**2, 'g', label=\"Residual\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time in s\")\n",
    "plt.show()\n",
    "\n",
    "# 2nd plot: spike train\n",
    "plt.figure(2)\n",
    "spikes_pos = np.array(np.nonzero(X))\n",
    "temporal_position = centers[spikes_pos[0][:]]\n",
    "centre_freq = freq_c[spikes_pos[1][:]]\n",
    "plt.scatter(temporal_position, centre_freq, marker='+', s=1)\n",
    "plt.show()\n",
    "\n",
    "# 3rd plot: example of gammatone-based dictionary\n",
    "fig = plt.figure(3)\n",
    "fig.suptitle(\"Gammatone filters\", fontsize=\"x-large\")\n",
    "freqs = [1000, 300, 40]\n",
    "resolution = 5000\n",
    "for center in [100, 1500, 3000]:\n",
    "    plt.subplot(311)\n",
    "    plt.plot(gammatone_function(resolution, freqs[0], center), linewidth=1.5)\n",
    "    plt.subplot(312)\n",
    "    plt.plot(gammatone_function(resolution, freqs[1], center+300), linewidth=1.5)\n",
    "    plt.ylabel(\"Kernel values\")\n",
    "    plt.subplot(313)\n",
    "    plt.plot(gammatone_function(resolution, freqs[2], center+1000), linewidth=1.5)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1.019\n",
    "resolution = 3600\n",
    "step = 8\n",
    "n_channels = 128\n",
    "overlap = 50\n",
    "\n",
    "g_1 = gammatone_function(resolution, fc= 600, center=200, fs=16000, b=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_1)\n",
    "plt.xlim([0, 600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(D_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
